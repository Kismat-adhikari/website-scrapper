# How Your Scraper Works on Apify

## ğŸ¯ Overview

Apify is a cloud platform for web scraping and automation. Your scraper becomes an **"Actor"** - a serverless application that runs in the cloud.

---

## ğŸ“Š Visual Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    APIFY PLATFORM                            â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  1. USER INPUT (Web UI or API)                     â”‚    â”‚
â”‚  â”‚     {                                               â”‚    â”‚
â”‚  â”‚       "urls": ["https://example.com"],             â”‚    â”‚
â”‚  â”‚       "maxConcurrency": 10,                        â”‚    â”‚
â”‚  â”‚       "depth": 2                                    â”‚    â”‚
â”‚  â”‚     }                                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  2. YOUR ACTOR STARTS                              â”‚    â”‚
â”‚  â”‚     - Loads your Python code                       â”‚    â”‚
â”‚  â”‚     - Reads input                                   â”‚    â”‚
â”‚  â”‚     - Initializes scraper                          â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  3. SCRAPING PROCESS                               â”‚    â”‚
â”‚  â”‚     - Visits websites                              â”‚    â”‚
â”‚  â”‚     - Extracts emails, phones, etc.                â”‚    â”‚
â”‚  â”‚     - Handles errors and retries                   â”‚    â”‚
â”‚  â”‚     - Saves progress                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  4. RESULTS SAVED                                  â”‚    â”‚
â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚    â”‚
â”‚  â”‚     â”‚  DATASET         â”‚ â† Scraped data (JSON/CSV) â”‚    â”‚
â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚    â”‚
â”‚  â”‚     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                           â”‚    â”‚
â”‚  â”‚     â”‚  KEY-VALUE STORE â”‚ â† Logs, resume data      â”‚    â”‚
â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                          â†“                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚  5. USER GETS RESULTS                              â”‚    â”‚
â”‚  â”‚     - Download as JSON/CSV/Excel                   â”‚    â”‚
â”‚  â”‚     - View in web interface                        â”‚    â”‚
â”‚  â”‚     - Access via API                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Step-by-Step: How It Works

### Step 1: User Provides Input

**Via Web UI:**
```
User goes to: https://console.apify.com/actors/YOUR_ACTOR_ID
Fills in form:
  - URLs: https://example.com, https://another.com
  - Max Concurrency: 10
  - Depth: 2
Clicks "Start"
```

**Via API:**
```bash
curl -X POST https://api.apify.com/v2/acts/YOUR_ACTOR_ID/runs \
  -H "Authorization: Bearer YOUR_API_TOKEN" \
  -d '{
    "urls": ["https://example.com"],
    "maxConcurrency": 10
  }'
```

---

### Step 2: Apify Starts Your Actor

```python
# Your main.py runs automatically
async with Actor:
    # Get input
    actor_input = await Actor.get_input()
    # actor_input = {"urls": ["https://example.com"], ...}
    
    # Your scraper starts
    scraper = WebsiteEmailScraper(config)
```

**What Apify Provides:**
- âœ… Cloud server (CPU, RAM)
- âœ… Headless browser (Playwright/Puppeteer)
- âœ… Proxy servers (optional)
- âœ… Storage (Dataset, Key-Value Store)
- âœ… Monitoring and logs

---

### Step 3: Scraping Happens

```python
# Your scraper runs in the cloud
for url in urls:
    # Scrape website
    data = await scraper.scrape_single_url(url)
    
    # Save to Apify Dataset (automatically synced)
    await Actor.push_data(data)
    
    # Save progress (for resume capability)
    await Actor.set_value('PROGRESS', progress_data)
```

**What Happens:**
1. Your scraper visits websites
2. Extracts emails, phones, addresses, socials
3. Handles popups automatically
4. Retries on failures
5. Saves results incrementally
6. Tracks progress

---

### Step 4: Results Are Saved

**Dataset (Main Results):**
```json
[
  {
    "url": "https://example.com",
    "emails": ["contact@example.com"],
    "phones": ["+1-555-123-4567"],
    "address": "123 Main St, City, State",
    "social_links": {...},
    "confidence_score": 0.95
  },
  {
    "url": "https://another.com",
    ...
  }
]
```

**Key-Value Store (Logs & Progress):**
```json
{
  "PROGRESS": {
    "processed": 50,
    "total": 100,
    "percentage": 50
  },
  "FAILED_URLS": [
    {"url": "https://failed.com", "reason": "timeout"}
  ],
  "FINAL_REPORT": {
    "total_urls": 100,
    "successful": 95,
    "failed": 5
  }
}
```

---

### Step 5: User Gets Results

**Download Options:**
- ğŸ“¥ JSON file
- ğŸ“¥ CSV file
- ğŸ“¥ Excel file
- ğŸ“¥ RSS feed
- ğŸ”— API access

**View in Browser:**
```
https://console.apify.com/actors/YOUR_ACTOR_ID/runs/LATEST/dataset
```

---

## ğŸ’° Pricing Model

### How Apify Charges:

**Compute Units (CU):**
- 1 CU = 1 hour of 1 CPU core + 1 GB RAM
- Example: Scraping 100 URLs might use 0.5 CU ($0.25)

**Free Tier:**
- $5 free credits per month
- ~20 CU hours free
- Good for testing and small projects

**Paid Plans:**
- Starter: $49/month (200 CU)
- Team: $499/month (2,500 CU)
- Enterprise: Custom pricing

---

## ğŸ¨ User Experience

### For End Users (Non-Technical):

**1. Find Your Actor:**
```
https://apify.com/store
Search: "Website Email Scraper"
Click: Your Actor
```

**2. Configure & Run:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Website Email Scraper              â”‚
â”‚                                     â”‚
â”‚  URLs to scrape:                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ https://example.com           â”‚ â”‚
â”‚  â”‚ https://another.com           â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                     â”‚
â”‚  Max Concurrency: [10]             â”‚
â”‚  Depth: [2]                        â”‚
â”‚                                     â”‚
â”‚  [Start] [Schedule]                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**3. Monitor Progress:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Run Status: Running...             â”‚
â”‚  Progress: 45/100 URLs (45%)        â”‚
â”‚  Duration: 2m 30s                   â”‚
â”‚  Emails Found: 67                   â”‚
â”‚  [View Log] [Stop]                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**4. Download Results:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Run Completed! âœ“                   â”‚
â”‚  Duration: 5m 12s                   â”‚
â”‚  URLs Processed: 100                â”‚
â”‚  Emails Found: 142                  â”‚
â”‚                                     â”‚
â”‚  [Download JSON] [Download CSV]     â”‚
â”‚  [Download Excel] [View Dataset]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Technical Details

### Your Code Structure on Apify:

```
YOUR_ACTOR/
â”œâ”€â”€ main.py                 # Entry point (runs automatically)
â”œâ”€â”€ scraper.py             # Your scraper code
â”œâ”€â”€ ultimate_scraper_optimized.py
â”œâ”€â”€ email_verification.py
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ .actor/
    â”œâ”€â”€ actor.json        # Actor metadata
    â””â”€â”€ input_schema.json # Input form definition
```

### What Apify Does Automatically:

1. **Installs Dependencies:**
   ```bash
   pip install -r requirements.txt
   playwright install chromium
   ```

2. **Runs Your Code:**
   ```bash
   python main.py
   ```

3. **Provides Environment:**
   - Headless browser
   - Proxy servers (if enabled)
   - Storage APIs
   - Monitoring

4. **Handles Scaling:**
   - Automatically scales resources
   - Manages memory
   - Handles crashes and restarts

---

## ğŸ“Š Example: Scraping 1,000 URLs

### Timeline:

```
0:00 - Actor starts
0:01 - Loads dependencies
0:02 - Begins scraping (10 concurrent)
0:05 - 100 URLs processed (10%)
0:10 - 200 URLs processed (20%)
...
0:50 - 1,000 URLs processed (100%)
0:51 - Generates final report
0:52 - Actor finishes
```

### Resources Used:
- **Time:** ~50 minutes
- **Compute:** ~0.8 CU
- **Cost:** ~$0.40
- **Results:** 1,000 websites scraped, ~500 emails found

---

## ğŸ¯ Key Benefits

### For You (Developer):
âœ… **No Server Management** - Apify handles infrastructure
âœ… **Automatic Scaling** - Handles 1 or 10,000 URLs
âœ… **Built-in Storage** - Dataset and Key-Value Store
âœ… **Monitoring** - Logs, metrics, alerts
âœ… **Marketplace** - Sell your Actor to others

### For Users:
âœ… **Easy to Use** - Web interface, no coding
âœ… **Reliable** - Automatic retries and error handling
âœ… **Fast** - Parallel processing
âœ… **Flexible** - API access, scheduling, webhooks

---

## ğŸš€ Deployment Process

### 1. Prepare Your Code:
```bash
# Your project structure
website-scraper/
â”œâ”€â”€ main.py                    # Apify entry point
â”œâ”€â”€ scraper.py                 # Your scraper
â”œâ”€â”€ ultimate_scraper_optimized.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ .actor/
    â”œâ”€â”€ actor.json
    â””â”€â”€ input_schema.json
```

### 2. Push to Apify:
```bash
# Install Apify CLI
npm install -g apify-cli

# Login
apify login

# Create Actor
apify create

# Push code
apify push
```

### 3. Test:
```bash
# Run locally
apify run

# Run on Apify
apify call
```

### 4. Publish:
```
Go to: https://console.apify.com/actors/YOUR_ACTOR_ID
Click: "Publish to Store"
Set price (free or paid)
Submit for review
```

---

## ğŸ’¡ Real-World Example

### Scenario: Marketing Agency

**Need:** Scrape 5,000 company websites to find contact emails

**Process:**
1. Upload CSV with 5,000 URLs to Apify
2. Configure Actor: maxConcurrency=20, depth=2
3. Click "Start"
4. Wait ~2 hours
5. Download results as Excel
6. Import to CRM

**Results:**
- 5,000 websites scraped
- 3,200 emails found
- 800 phone numbers found
- Cost: ~$2.00
- Time saved: 100+ hours of manual work

---

## ğŸ‰ Summary

**How It Works:**
1. User provides URLs via web UI or API
2. Apify starts your Actor in the cloud
3. Your scraper runs and extracts data
4. Results saved to Dataset automatically
5. User downloads results (JSON/CSV/Excel)

**Key Features:**
- âœ… Runs in cloud (no local setup needed)
- âœ… Handles 1 to 10,000+ URLs
- âœ… Automatic retries and error handling
- âœ… Resume capability if interrupted
- âœ… Easy to use for non-technical users
- âœ… Can be sold on Apify Marketplace

**Your scraper becomes a professional, scalable service that anyone can use!** ğŸš€
